{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->The majority of practical machine learning uses supervised learning.\n",
    "\n",
    "-->Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm      to learn the mapping function from the input to the output.\n",
    "\n",
    "                                                Y = f(X)\n",
    "\n",
    "-->The goal is to approximate the mapping function so well that when you have new input data (x) that you can        predict the output variables (Y) for that data.\n",
    "\n",
    "-->It is called supervised learning because the process of an algorithm learning from the training dataset can be    thought of as a teacher supervising the learning process. We know the correct answers, the algorithm              iteratively makes predictions on the training data and is corrected by the teacher. Learning stops when the        algorithm achieves an acceptable level of performance.\n",
    "\n",
    "Supervised learning problems can be further grouped into regression and classification problems.\n",
    "\n",
    "Classification: A classification problem is when the output variable is a category, such as “red” or “blue” or                     “disease” and “no disease”.\n",
    "Regression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\n",
    "            Some common types of problems built on top of classification and regression include recommendation and             time series prediction respectively.\n",
    "\n",
    "Some popular examples of supervised machine learning algorithms are:\n",
    "\n",
    "-->Linear regression for regression problems.\n",
    "-->Random forest for classification and regression problems.\n",
    "-->Support vector machines for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Regression \n",
    "    •Linear Regression - One Variable \n",
    "    •Linear Regression - Multivariable \n",
    "    •Logistic Regression Classification\n",
    "2.Naive Bayes \n",
    "3.Support Vector Machines (SVMs) \n",
    "4.Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->Linear Regression is a method used to define a relationship between a dependent variable (Y) and independent variable (X). Which is simply written as: \n",
    "                                \n",
    "                                y=mx+b-----------------------Linear Regression-One Variable\n",
    "                                where, m->slope\n",
    "                                       b->intercept\n",
    "                                y=a0 + a1x1 + a2X2 + ...-----Linear Regression-Multi Variable\n",
    "                                where, there are multiple x \n",
    "                    \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - One Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n",
      "Intercept: \n",
      " -99.46431881371655\n",
      "Coefficients: \n",
      " [564.20389249]\n",
      "Enter Interest Rate: 2.7\n",
      "Predicted Stock Index Price: \n",
      " [1423.88619092]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import linear_model\n",
    "# Reading Data\n",
    "\n",
    "data = pd.read_csv('multi_var_regression1.csv')\n",
    "df = pd.DataFrame(data,columns=['Year','Month','Interest_Rate','Unemployment_Rate','Stock_Index_Price'])\n",
    "X = df[['Interest_Rate']]# here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "Y = df['Stock_Index_Price']\n",
    "\n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "#verbose=1\n",
    "regr.fit(X, Y)\n",
    "print(regr.fit(X, Y))\n",
    "\n",
    "print ('Intercept: \\n', regr.intercept_)\n",
    "print ('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "# prediction with sklearn\n",
    "#New_Interest_Rate = 2.75\n",
    "#print(type(New_Interest_Rate))\n",
    "# New_Unemployment_Rate = 5.3\n",
    "\n",
    "New_Interest_Rate = float(input('Enter Interest Rate: '))\n",
    "print ('Predicted Stock Index Price: \\n', regr.predict([[New_Interest_Rate]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Multivariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 1798.4039776258546\n",
      "Coefficients: \n",
      " [ 345.54008701 -250.14657137]\n",
      "Enter Interest Rate: 2.7\n",
      "Enter Unemployment Rate: 5.3\n",
      "Predicted Stock Index Price: \n",
      " [1405.5853843]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "X = df[['Interest_Rate','Unemployment_Rate']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "Y = df['Stock_Index_Price']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print ('Intercept: \\n', regr.intercept_)\n",
    "print ('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "# prediction with sklearn\n",
    "# New_Interest_Rate = 2.75\n",
    "# New_Unemployment_Rate = 5.3\n",
    "\n",
    "New_Interest_Rate = float(input('Enter Interest Rate: '))\n",
    "New_Unemployment_Rate = float(input('Enter Unemployment Rate: '))\n",
    "print ('Predicted Stock Index Price: \\n', regr.predict([[New_Interest_Rate ,New_Unemployment_Rate]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->Logistic regression is another technique borrowed by machine learning from the field of statistics.\n",
    "-->It is the go-to method for binary classification problems (problems with two class values). In this post you      will discover the logistic regression algorithm for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[[8.78030305e-01 1.21958900e-01 1.07949250e-05]\n",
      " [7.97058292e-01 2.02911413e-01 3.02949242e-05]]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishali/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vaishali/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Uncomment while using manual input\n",
    "# data = pd.read_csv('Iris.csv')\n",
    "# X = data.drop(['Id', 'Species'], axis=1)\n",
    "# y = data['Species']\n",
    "\n",
    "# Comment while using manual input\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Comment while using manual input\n",
    "print (clf.predict(X[:2, :]))\n",
    "print (clf.predict_proba(X[:2, :]))\n",
    "print (clf.score(X, y))\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Uncomment while using manual input\n",
    "# X = input('Enter values SepalLength SepalWidth PetalLength PetalWidth:')\n",
    "# y_pred = clf.predict(X)\n",
    "# print y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->Naive Bayes models are a group of extremely fast and simple classification algorithms that are suitable for very high dimensional datasets.\n",
    "-->Easiest Naive Bayes classifier to understand is Gaussian Naive Bayes\n",
    "-->In this classfier,the assumption is that from each label is drawn from a simple Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(iris.data, iris.target)\n",
    "#X = []\n",
    "#X1 =(input('Enter values SepalLength SepalWidth PetalLength PetalWidth:').split())\n",
    "X=[7.1,3,5.9,2.1]\n",
    "#for item in X1:\n",
    "#    X.append(float(item))\n",
    "#print(X)\n",
    "y_pred = gnb.predict([X])\n",
    "#7.1,3,5.9,2.1\n",
    "if y_pred==0:\n",
    "    print ('Iris-setosa')\n",
    "elif y_pred==1:\n",
    "    print ('Iris-versicolor')\n",
    "else:\n",
    "    print ('Iris-virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->Support Vector Machines(SVMs) are a particularly powerul and flexible class of supervised algorithms for both classification and regression\n",
    "-->Here we are using SVM for Classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.50942546]\n",
      "Iris-virginica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishali/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "data = pd.read_csv('Iris1.csv')\n",
    "X = data.drop(['Id', 'Species'], axis=1)\n",
    "y = data['Species']\n",
    "\n",
    "clf = svm.SVR()\n",
    "clf.fit(X,y);\n",
    "X=[7.1,3,5.9,2.1]\n",
    "#X = input('Enter values SepalLength SepalWidth PetalLength PetalWidth:')\n",
    "y_pred = clf.predict([X])\n",
    "\n",
    "if 0<y_pred<10:\n",
    "    print ('Iris-setosa')\n",
    "elif 10<y_pred<20:\n",
    "    print ('Iris-versicolor')\n",
    "else:\n",
    "    print ('Iris-virginica')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees in Machine Learning\n",
    "### A tree has many analogies in real life, and turns out that it has influenced a wide area of machine learning, covering both classification and regression. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "iris = load_iris()\n",
    "\n",
    "cross_val_score(clf, iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
